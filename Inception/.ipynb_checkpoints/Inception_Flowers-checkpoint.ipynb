{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from random import sample\n",
    "height = 299\n",
    "width = 299\n",
    "channels = 3\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "FLOWERS_PATH=\"./datasets/flowers\"\n",
    "paths_and_classes = []\n",
    "count = 1\n",
    "label = 0\n",
    "for filepath in os.listdir(FLOWERS_PATH):\n",
    "    if filepath.endswith(\".jpg\"):\n",
    "        paths_and_classes.append((os.path.join(FLOWERS_PATH,filepath), label))\n",
    "        if(count%80 == 0):\n",
    "            label = count // 80\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "def prepare_image(image, target_width = 299, target_height = 299, max_zoom = 0.2):\n",
    "    # First, let's find the largest bounding box with the target size ratio that fits within the image\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    image_ratio = width / height\n",
    "    target_image_ratio = target_width / target_height\n",
    "    crop_vertically = image_ratio < target_image_ratio\n",
    "    crop_width = width if crop_vertically else int(height * target_image_ratio)\n",
    "    crop_height = int(width / target_image_ratio) if crop_vertically else height\n",
    "        \n",
    "    resize_factor = np.random.rand() * max_zoom + 1.0\n",
    "    crop_width = int(crop_width / resize_factor)\n",
    "    crop_height = int(crop_height / resize_factor)\n",
    "    \n",
    "    x0 = np.random.randint(0, width - crop_width)\n",
    "    y0 = np.random.randint(0, height - crop_height)\n",
    "    x1 = x0 + crop_width\n",
    "    y1 = y0 + crop_height\n",
    "    \n",
    "    image = image[y0:y1, x0:x1]\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = np.fliplr(image)\n",
    "    image = resize(image, (target_width, target_height))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zdunkerton\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "split_ratio = .8\n",
    "num_train = int(len(paths_and_classes)*split_ratio)\n",
    "np.random.shuffle(paths_and_classes)\n",
    "train = paths_and_classes[:num_train]\n",
    "test = paths_and_classes[num_train:]\n",
    "def prepare_batch(paths_and_classes, batch_size):\n",
    "    batch_paths_and_classes = sample(paths_and_classes, batch_size)\n",
    "    images = [mpimg.imread(path)[:, :, :channels] for path, labels in batch_paths_and_classes]\n",
    "    prepared_images = [prepare_image(image) for image in images]\n",
    "    X_batch = 2 * np.stack(prepared_images) - 1\n",
    "    y_batch = np.array([labels for path, labels in batch_paths_and_classes], dtype=np.int32)\n",
    "    return X_batch, y_batch\n",
    "X_test, y_test = prepare_batch(test, len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zdunkerton\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.slim.nets import inception\n",
    "import tensorflow.contrib.slim as slim\n",
    "INCEPTION_PATH = os.path.join(\"datasets\", \"inception\")\n",
    "INCEPTION_V3_CHECKPOINT_PATH = os.path.join(INCEPTION_PATH, \"inception_v3.ckpt\")\n",
    "height = 299\n",
    "width = 299\n",
    "channels = 3\n",
    "reset_graph()\n",
    "X = tf.placeholder(tf.float32, shape=[None, height, width, channels], name=\"X\")\n",
    "training = tf.placeholder_with_default(False, shape=[])\n",
    "with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "    logits, end_points = inception.inception_v3(X, num_classes=1001, is_training=training)\n",
    "\n",
    "inception_saver = tf.train.Saver()\n",
    "prelogits = tf.squeeze(end_points[\"PreLogits\"], axis=[1, 2])\n",
    "n_outputs = 17\n",
    "\n",
    "with tf.name_scope(\"new_output_layer\"):\n",
    "    flower_logits = tf.layers.dense(prelogits, n_outputs, name=\"flower_logits\")\n",
    "    Y_proba = tf.nn.softmax(flower_logits, name=\"Y_proba\")\n",
    "    \n",
    "y = tf.placeholder(tf.int32, shape=[None])\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=flower_logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    flower_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"flower_logits\")\n",
    "    training_op = optimizer.minimize(loss, var_list=flower_vars)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(flower_logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver() \n",
    "\n",
    "X_test, y_test = prepare_batch(test, batch_size=len(test))\n",
    "n_epochs = 10\n",
    "batch_size = 40\n",
    "n_iterations_per_epoch = len(train) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from datasets\\inception\\inception_v3.ckpt\n",
      "Epoch 0."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zdunkerton\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................  Train accuracy: 0.4\n",
      "Epoch 1...........................  Train accuracy: 0.375\n",
      "Epoch 2...........................  Train accuracy: 0.325\n",
      "Epoch 3...........................  Train accuracy: 0.575\n",
      "Epoch 4...........................  Train accuracy: 0.475\n",
      "Epoch 5...........................  Train accuracy: 0.45\n",
      "Epoch 6...........................  Train accuracy: 0.45\n",
      "Epoch 7...........................  Train accuracy: 0.5\n",
      "Epoch 8...........................  Train accuracy: 0.475\n",
      "Epoch 9...........................  Train accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    inception_saver.restore(sess, INCEPTION_V3_CHECKPOINT_PATH)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch\", epoch, end=\"\")\n",
    "        for iteration in range(n_iterations_per_epoch):\n",
    "            print(\".\", end=\"\")\n",
    "            X_batch, y_batch = prepare_batch(train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        print(\"  Train accuracy:\", acc_train)\n",
    "\n",
    "        save_path = saver.save(sess, \"./my_flower_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_flower_model\n",
      "Test accuracy: 0.53571427\n"
     ]
    }
   ],
   "source": [
    "n_test_batches = 10\n",
    "X_test_batches = np.array_split(X_test, n_test_batches)\n",
    "y_test_batches = np.array_split(y_test, n_test_batches)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_flower_model\")\n",
    "    acc_test = np.mean([\n",
    "        accuracy.eval(feed_dict={X: X_test_batch, y: y_test_batch})\n",
    "        for X_test_batch, y_test_batch in zip(X_test_batches, y_test_batches)])\n",
    "    print(\"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
