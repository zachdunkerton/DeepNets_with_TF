{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code reads in the data, and saves it in numpy arrays for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from netCDF4 import Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through all of the files in the data folder, and extract the desired variable. In this case, that variable is the lattitude and logintude grid of that value. For example, the air temperature data is a grid of temperatures, corresponding to different locations on the globe. From each value, 16 years of data are read in and stored by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder = \"C:/users/zdunkerton/documents/githubdata/hurricane/initial_data\"\n",
    "for dir in os.listdir(folder):\n",
    "    data = []\n",
    "    time = []\n",
    "    for filename in os.listdir(folder+\"/\"+dir):\n",
    "        x = Dataset(folder+\"/\"+dir+\"/\"+filename,'r').variables[filename.split('.')[0]]\n",
    "        y = Dataset(folder+\"/\"+dir+\"/\"+filename,'r').variables[\"time\"]\n",
    "        if(x.shape[0]>1460):\n",
    "            x =x[:1460,:,:]\n",
    "            y = y[:1460]\n",
    "        time.append(y)\n",
    "        data.append(x)\n",
    "    time = np.array(time)\n",
    "    time = np.reshape(time, (23360,))\n",
    "    data = np.array(data)\n",
    "    time_name = \"C:/Users/zdunkerton/Documents/GitHubData/Hurricane/Preprocessed/time.npy\"\n",
    "    data_name = \"./\"+dir+\".npy\"\n",
    "    np.save(time_name, time)\n",
    "    np.save(data_name, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am saving and reloading the variables so I have them, but this isn't necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.load(\"C:/Users/zdunkerton/Documents/GitHubData/Hurricane/Preprocessed/Temp_Surface_4xDaily.npy\")\n",
    "wind = np.load(\"C:/Users/zdunkerton/Documents/GitHubData/Hurricane/Preprocessed/UWind_Surface_4xDaily.npy\")\n",
    "humd = np.load(\"C:/Users/zdunkerton/Documents/GitHubData/Hurricane/Preprocessed/RelativeHumidity_Surface_4xDaily.npy\")\n",
    "press = np.load(\"C:/Users/zdunkerton/Documents/GitHubData/Hurricane/Preprocessed/Pressure_Surface_4xDaily.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data on date at a time. For each data, read in the four values and stack them on top of each other. These layers all correspond to the same point in time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23360, 4, 73, 144)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 0\n",
    "data= []\n",
    "while year < temp.shape[0]:\n",
    "    day = 0\n",
    "    while day < temp.shape[1]:\n",
    "        temp1 = temp[year][day]\n",
    "        temp1 = scaler.fit_transform(temp1)\n",
    "        wind1 = wind[year][day]\n",
    "        wind1 = scaler.fit_transform(wind1)\n",
    "        humd1 = humd[year][day]\n",
    "        humd1 = scaler.fit_transform(humd1)\n",
    "        pres1 = press[year][day]\n",
    "        pres1 = scaler.fit_transform(pres1)\n",
    "        the_data = np.array([temp1,wind1,humd1,pres1])\n",
    "        data.append(the_data)\n",
    "        day+=1\n",
    "    year+=1\n",
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Preprocessed_data.npy\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1753158.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "date1 = datetime.datetime(1800,1,1,0,0)\n",
    "date2 = datetime.datetime(2000,1,1,6,0)\n",
    "(date2-date1).total_seconds()/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.load(\"C:/Users/zdunkerton/Documents/GitHubData/Hurricane/Preprocessed/time.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1753158.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./atlantic.csv\")\n",
    "df = df.loc[df[\"Status\"]==\"HU\"]\n",
    "df = df.loc[df['Date']>20000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ID', 'Name', 'Date', 'Time', 'Event', 'Status', 'Latitude',\n",
       "       'Longitude', 'Maximum Wind', 'Minimum Pressure', 'Low Wind NE',\n",
       "       'Low Wind SE', 'Low Wind SW', 'Low Wind NW', 'Moderate Wind NE',\n",
       "       'Moderate Wind SE', 'Moderate Wind SW', 'Moderate Wind NW',\n",
       "       'High Wind NE', 'High Wind SE', 'High Wind SW', 'High Wind NW'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datetime.datetime(int(str(df.iloc[0,2])[:4]), int(str(df.iloc[0,2])[4:6]),int(str(df.iloc[0,2])[7:8]),df.iloc[0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_time = 915\n",
    "the_time !=0 & the_time !=600 & the_time !=1200 & the_time !=1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "date1 = datetime.datetime(1800,1,1,0,0)\n",
    "hurricane_times = []\n",
    "while i<len(df):\n",
    "    the_time = df.iloc[i,3]\n",
    "    if the_time !=0 & the_time !=600 & the_time !=1200 & the_time !=1800:\n",
    "        if the_time <=900:\n",
    "            df.iloc[i,3] = 600\n",
    "        elif the_time >900 & the_time<=1500:\n",
    "            df.iloc[i,3] = 1200\n",
    "        elif the_time >1800:\n",
    "            df.iloc[i,3] = 1800\n",
    "    hurricane_time = datetime.datetime(int(str(df.iloc[i,2])[:4]), int(str(df.iloc[i,2])[4:6]),int(str(df.iloc[i,2])[6:8]),int(df.iloc[i,3]/100))\n",
    "    converted_time = (hurricane_time-date1).total_seconds()/3600\n",
    "    hurricane_times.append(converted_time)\n",
    "    if converted_time not in time:\n",
    "        print(df.iloc[i,3])\n",
    "    i+=1\n",
    "hurricane_times = sorted(hurricane_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for t in time:\n",
    "    if t in hurricane_times:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for t in hurricane_times:\n",
    "    if t in time:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for x in labels:\n",
    "    if x == 1:\n",
    "        count+=1\n",
    "len(hurricane_times) - count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23360"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
