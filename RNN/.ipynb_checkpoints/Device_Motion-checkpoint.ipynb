{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify by Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"C:/users/zdunkerton/documents/githubdata/A_DeviceMotion_data/A_DeviceMotion_data\"\n",
    "label = -1\n",
    "the_data = []\n",
    "labels = []\n",
    "for dir in os.listdir(folder):\n",
    "    for file in os.listdir(os.path.join(folder,dir)):\n",
    "        data = pd.read_csv(os.path.join(folder,dir, file))\n",
    "        data = data.iloc[:,1:13].values\n",
    "        num_steps = 100\n",
    "        for iteration in range(len(data)//num_steps):\n",
    "            x = data[(iteration*num_steps):((iteration+1)*num_steps)]\n",
    "            the_data.append(x)\n",
    "            num = int(file.split(\"_\")[1].split(\".\")[0])-1\n",
    "            labels.append(num)\n",
    "the_data = np.array(the_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(the_data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify by action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"C:/users/zdunkerton/documents/githubdata/A_DeviceMotion_data/A_DeviceMotion_data\"\n",
    "label = -1\n",
    "the_data = []\n",
    "labels = []\n",
    "for dir in os.listdir(folder):\n",
    "    if dir.split(\"_\")[0]==\"dws\":\n",
    "        label = 0\n",
    "    elif dir.split(\"_\")[0]==\"jog\":\n",
    "        label = 1\n",
    "    elif dir.split(\"_\")[0]==\"sit\":\n",
    "        label = 2\n",
    "    elif dir.split(\"_\")[0]==\"std\":\n",
    "        label = 3\n",
    "    elif dir.split(\"_\")[0]==\"ups\":\n",
    "        label = 4\n",
    "    elif dir.split(\"_\")[0]==\"wlk\":\n",
    "        label = 5\n",
    "    for file in os.listdir(os.path.join(folder,dir)):\n",
    "        data = pd.read_csv(os.path.join(folder,dir, file))\n",
    "        data = data.iloc[:,1:13].values\n",
    "        num_steps = 100\n",
    "        for iteration in range(len(data)//num_steps):\n",
    "            x = data[(iteration*num_steps):((iteration+1)*num_steps)]\n",
    "            the_data.append(x)\n",
    "            labels.append(label)\n",
    "the_data = np.array(the_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(the_data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify by Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender ~90% Accuracy\n",
    "\n",
    "Age (three categories) ~84% (probably could get higher with more ephochs)\n",
    "\n",
    "Weight ~83% (same as above) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     28.859212\n",
       "1     22.222222\n",
       "2     18.517804\n",
       "3     29.054752\n",
       "4     17.846520\n",
       "5     23.456790\n",
       "6     20.244898\n",
       "7     20.060954\n",
       "8     25.761773\n",
       "9     26.769780\n",
       "10    22.093170\n",
       "11    21.513859\n",
       "12    18.937003\n",
       "13    21.604938\n",
       "14    20.452885\n",
       "15    32.449973\n",
       "16    23.456790\n",
       "17    20.077335\n",
       "18    29.000595\n",
       "19    27.160494\n",
       "20    19.100092\n",
       "21    28.905076\n",
       "22    23.529412\n",
       "23    24.725183\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_data[\"weight\"]/((subject_data[\"height\"]/100)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  5  7  8 13 15 18 21]\n",
      "[ 2  6 11 12 14 17 23 24]\n",
      "[ 1  4  9 10 16 19 20 22]\n"
     ]
    }
   ],
   "source": [
    "subject_data = pd.read_csv(\"C:/users/zdunkerton/documents/githubdata/A_DeviceMotion_data/data_subjects_info.csv\")\n",
    "zero = subject_data.loc[(subject_data[\"weight\"]/((subject_data[\"height\"]/100)**2)) <= 21]\n",
    "zero = zero[\"code\"].values\n",
    "one = subject_data.loc[((subject_data[\"weight\"]/((subject_data[\"height\"]/100)**2)) >21) & \n",
    "                       ((subject_data[\"weight\"]/((subject_data[\"height\"]/100)**2))<=25)]\n",
    "one = one[\"code\"].values\n",
    "two = subject_data.loc[((subject_data[\"weight\"]/((subject_data[\"height\"]/100)**2)) >25)]\n",
    "two = two[\"code\"].values\n",
    "#three = subject_data.loc[((subject_data[\"weight\"]/((subject_data[\"height\"]/100)**2)) >29)]\n",
    "#three = three[\"code\"].values\n",
    "print(zero)\n",
    "print(one)\n",
    "print(two)\n",
    "#print(three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = subject_data.loc[subject_data[\"code\"] == 8]\n",
    "test[\"age\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"C:/users/zdunkerton/documents/githubdata/A_DeviceMotion_data/A_DeviceMotion_data\"\n",
    "label = -1\n",
    "the_data = []\n",
    "labels = []\n",
    "for dir in os.listdir(folder):\n",
    "    for file in os.listdir(os.path.join(folder,dir)):\n",
    "        num = int(file.split(\"_\")[1].split(\".\")[0])\n",
    "        data = pd.read_csv(os.path.join(folder,dir, file))\n",
    "        data = data.iloc[:,1:13].values\n",
    "        num_steps = 20\n",
    "        for iteration in range(len(data)//num_steps):\n",
    "            x = data[(iteration*num_steps):((iteration+1)*num_steps)]\n",
    "            the_data.append(x)\n",
    "            if num in zero:\n",
    "                labels.append(0)\n",
    "            elif num in one:\n",
    "                labels.append(1)\n",
    "            elif num in two:\n",
    "                labels.append(2)\n",
    "            #elif num in three:\n",
    "                #labels.append(3)\n",
    "the_data = np.array(the_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(the_data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch_size, index):\n",
    "    return X_train[index:(index+batch_size)], y_train[index:(index+batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_steps = 20\n",
    "n_inputs = 12\n",
    "n_neurons = 100\n",
    "n_outputs = 24\n",
    "n_layers = 2\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "lstm_cells = [tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\n",
    "              for layer in range(n_layers)]\n",
    "multi_cell = tf.contrib.rnn.MultiRNNCell(lstm_cells)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)\n",
    "top_layer_h_state = states[-1][1]\n",
    "logits = tf.layers.dense(top_layer_h_state, n_outputs, name=\"softmax\")\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.76 Test accuracy: 0.75313634\n",
      "1 Train accuracy: 0.84 Test accuracy: 0.8042488\n",
      "2 Train accuracy: 0.84 Test accuracy: 0.8289539\n",
      "3 Train accuracy: 0.88 Test accuracy: 0.8441394\n",
      "4 Train accuracy: 0.9 Test accuracy: 0.8545225\n",
      "5 Train accuracy: 0.9066667 Test accuracy: 0.8627399\n",
      "6 Train accuracy: 0.91333336 Test accuracy: 0.8687773\n",
      "7 Train accuracy: 0.9066667 Test accuracy: 0.8735123\n",
      "8 Train accuracy: 0.91333336 Test accuracy: 0.87686014\n",
      "9 Train accuracy: 0.9066667 Test accuracy: 0.8800027\n",
      "10 Train accuracy: 0.9 Test accuracy: 0.8824622\n",
      "11 Train accuracy: 0.9 Test accuracy: 0.88426\n",
      "12 Train accuracy: 0.8933333 Test accuracy: 0.8858419\n",
      "13 Train accuracy: 0.9 Test accuracy: 0.88747686\n",
      "14 Train accuracy: 0.9 Test accuracy: 0.8885279\n",
      "15 Train accuracy: 0.9066667 Test accuracy: 0.8898196\n",
      "16 Train accuracy: 0.91333336 Test accuracy: 0.89122456\n",
      "17 Train accuracy: 0.92 Test accuracy: 0.8923641\n",
      "18 Train accuracy: 0.92 Test accuracy: 0.89317805\n",
      "19 Train accuracy: 0.92 Test accuracy: 0.8941513\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(X_train.shape[0] // batch_size):\n",
    "            X_batch, y_batch = next_batch(batch_size, iteration*batch_size)\n",
    "            #X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
