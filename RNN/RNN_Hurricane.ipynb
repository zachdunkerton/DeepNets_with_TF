{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"C:/Users/zdunkerton/Documents/GitHubData/Hurricane/final_data/Preprocessed_data.npy\")\n",
    "labels = np.load(\"C:/Users/zdunkerton/Documents/GitHubData/Hurricane/final_data/labels.npy\")\n",
    "X_train, y_train = data[:int(len(data)*.8)], labels[:int(len(data)*.8)]\n",
    "X_test, y_test = data[int(len(data)*.8):], labels[int(len(data)*.8):]\n",
    "X_test = np.reshape(X_test, (-1, 292,144))\n",
    "data= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"C:/Users/zdunkerton/Documents/GitHubData/Hurricane/final_data/Preprocessed_data.npy\")\n",
    "labels = np.load(\"C:/Users/zdunkerton/Documents/GitHubData/Hurricane/final_data/labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "hurricanes = []\n",
    "new_labels = []\n",
    "add_zero = False\n",
    "index = 0\n",
    "while index < len(data):\n",
    "    if labels[index] ==1:\n",
    "        hurricanes.append(data[index])\n",
    "        new_labels.append(1)\n",
    "    index+=1\n",
    "    \n",
    "index =0\n",
    "count = 0\n",
    "length = len(hurricanes)\n",
    "while count < length:\n",
    "    if labels[index] == 0:\n",
    "        hurricanes.append(data[index])\n",
    "        new_labels.append(0)\n",
    "        count +=1\n",
    "    index +=1\n",
    "hurricanes = np.array(hurricanes)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(hurricanes, new_labels, test_size=0.2, random_state=42)\n",
    "X_test = np.reshape(X_test, (-1, 292, 144))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch_size, index):\n",
    "    X = X_train[index:(index+batch_size)]\n",
    "    X = np.reshape(X, (-1, 292, 144))\n",
    "    return X, y_train[index:(index+batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_steps = 292\n",
    "n_inputs = 144\n",
    "n_neurons = 100\n",
    "n_outputs = 2\n",
    "n_layers = 5\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "lstm_cells = [tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\n",
    "              for layer in range(n_layers)]\n",
    "multi_cell = tf.contrib.rnn.MultiRNNCell(lstm_cells)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)\n",
    "top_layer_h_state = states[-1][1]\n",
    "logits = tf.layers.dense(top_layer_h_state, n_outputs, name=\"softmax\")\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(X_train.shape[0] // batch_size):\n",
    "            X_batch, y_batch = next_batch(batch_size, iteration*batch_size)\n",
    "            #X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.111515410958905"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "for i in y_train:\n",
    "    if i ==1:\n",
    "        count +=1\n",
    "(count / len(y_train))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next_batch(10,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = k.reshape(42048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
