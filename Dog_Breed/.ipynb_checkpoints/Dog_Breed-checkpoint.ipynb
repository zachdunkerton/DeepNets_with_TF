{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Classification using Pretrained Inception Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code classifies dog breeds using the pretrained inception model\n",
    "\n",
    "Based on code from Aurelien Geron https://github.com/ageron/handson-ml/blob/master/13_convolutional_neural_networks.ipynb\n",
    "\n",
    "Dataset: https://www.kaggle.com/c/dog-breed-identification/data\n",
    "\n",
    "I am not able to run this code on my current machine, so I do not have any performance metrics/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the file paths, and add class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "labels = pd.read_csv(\"./datasets/labels.csv\")\n",
    "\n",
    "TRAIN_PATH=\"./datasets/train\"\n",
    "TEST_PATH=\"./datasets/test\"\n",
    "paths_and_classes = []\n",
    "train_paths = []\n",
    "\n",
    "dog_class = labels[\"breed\"].unique()\n",
    "dog_class_ids = {dog_class: index for index, dog_class in enumerate(dog_class)}\n",
    "\n",
    "for filepath in os.listdir(TRAIN_PATH):\n",
    "    _id = labels.loc[labels[\"id\"]==filepath.split(\".\")[0]]\n",
    "    paths_and_classes.append((os.path.join(TRAIN_PATH,filepath), dog_class_ids[_id.iloc[0][\"breed\"]]))\n",
    "\n",
    "for filepath in os.listdir(TEST_PATH):\n",
    "    train_paths.append(os.path.join(TEST_PATH,filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download incpetion model, A. Geron's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "TF_MODELS_URL = \"http://download.tensorflow.org/models\"\n",
    "INCEPTION_V3_URL = TF_MODELS_URL + \"/inception_v3_2016_08_28.tar.gz\"\n",
    "INCEPTION_PATH = os.path.join(\"datasets\", \"inception\")\n",
    "INCEPTION_V3_CHECKPOINT_PATH = os.path.join(INCEPTION_PATH, \"inception_v3.ckpt\")\n",
    "\n",
    "def download_progress(count, block_size, total_size):\n",
    "    percent = count * block_size * 100 // total_size\n",
    "    sys.stdout.write(\"\\rDownloading: {}%\".format(percent))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def fetch_pretrained_inception_v3(url=INCEPTION_V3_URL, path=INCEPTION_PATH):\n",
    "    if os.path.exists(INCEPTION_V3_CHECKPOINT_PATH):\n",
    "        return\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    tgz_path = os.path.join(path, \"inception_v3.tgz\")\n",
    "    urllib.request.urlretrieve(url, tgz_path, reporthook=download_progress)\n",
    "    inception_tgz = tarfile.open(tgz_path)\n",
    "    inception_tgz.extractall(path=path)\n",
    "    inception_tgz.close()\n",
    "    os.remove(tgz_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = .9\n",
    "num_train = int(len(paths_and_classes)*split_ratio)\n",
    "np.random.shuffle(paths_and_classes)\n",
    "train = paths_and_classes[:num_train]\n",
    "val = paths_and_classes[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop and resize the image. Method from A. Geron. \n",
    "Prepare batch preps the image and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "import matplotlib.image as mpimg\n",
    "channels = 3\n",
    "def prepare_image(image, target_width = 299, target_height = 299, max_zoom = 0.2):\n",
    "    # First, let's find the largest bounding box with the target size ratio that fits within the image\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    image_ratio = width / height\n",
    "    target_image_ratio = target_width / target_height\n",
    "    crop_vertically = image_ratio < target_image_ratio\n",
    "    crop_width = width if crop_vertically else int(height * target_image_ratio)\n",
    "    crop_height = int(width / target_image_ratio) if crop_vertically else height\n",
    "        \n",
    "    resize_factor = np.random.rand() * max_zoom + 1.0\n",
    "    crop_width = int(crop_width / resize_factor)\n",
    "    crop_height = int(crop_height / resize_factor)\n",
    "    \n",
    "    x0 = np.random.randint(0, width - crop_width)\n",
    "    y0 = np.random.randint(0, height - crop_height)\n",
    "    x1 = x0 + crop_width\n",
    "    y1 = y0 + crop_height\n",
    "    \n",
    "    image = image[y0:y1, x0:x1]\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = np.fliplr(image)\n",
    "    image = resize(image, (target_width, target_height))\n",
    "    return image\n",
    "\n",
    "def prepare_batch(index, batch_size,data):\n",
    "    batch_paths_and_classes = data[index:(index+batch_size)]\n",
    "    images = [mpimg.imread(path)[:, :, :channels] for path, labels in batch_paths_and_classes]\n",
    "    prepared_images = [prepare_image(image) for image in images]\n",
    "    X_batch = 2 * np.stack(prepared_images) - 1 # Inception expects colors ranging from -1 to 1\n",
    "    X_batch = np.stack(prepared_images)\n",
    "    y_batch = np.array([labels for path, labels in batch_paths_and_classes], dtype=np.int32)\n",
    "    return X_batch, y_batch\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the inception model and replace the top layer with the number of classes (120). Run standard train and optimization steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.slim.nets import inception\n",
    "import tensorflow.contrib.slim as slim\n",
    "INCEPTION_PATH = os.path.join(\"datasets\", \"inception\")\n",
    "INCEPTION_V3_CHECKPOINT_PATH = os.path.join(INCEPTION_PATH, \"inception_v3.ckpt\")\n",
    "height = 299\n",
    "width = 299\n",
    "channels = 3\n",
    "reset_graph()\n",
    "X = tf.placeholder(tf.float32, shape=[None, height, width, channels], name=\"X\")\n",
    "training = tf.placeholder_with_default(False, shape=[])\n",
    "with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "    logits, end_points = inception.inception_v3(X, num_classes=1001, is_training=training)\n",
    "\n",
    "inception_saver = tf.train.Saver()\n",
    "prelogits = tf.squeeze(end_points[\"PreLogits\"], axis=[1, 2])\n",
    "extra_layer = tf.layers.dense(prelogits, 750)\n",
    "extra_layer_2 = tf.layers.dense(extra_layer, 400)\n",
    "extra_layer_3 = tf.layers.dense(extra_layer_2, 250)\n",
    "n_outputs = 120\n",
    "\n",
    "with tf.name_scope(\"new_output_layer\"):\n",
    "    dog_logits = tf.layers.dense(extra_layer_3, n_outputs, name=\"dog_logits\")\n",
    "    Y_proba = tf.nn.softmax(dog_logits, name=\"Y_proba\")\n",
    "    \n",
    "y = tf.placeholder(tf.int32, shape=[None])\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=dog_logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    dog_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"dog_logits\")\n",
    "    training_op = optimizer.minimize(loss, var_list=dog_vars)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(dog_logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from datasets\\inception\\inception_v3.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zach dunkerton\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations Remaining: 1.00, Time 15.61s, Est. Time Remainig: 0.26 minnnn  Train accuracy: 0.775\n",
      "Iterations Remaining: 1.00, Time 15.00s, Est. Time Remainig: 0.25 minnnn  Train accuracy: 0.775\n",
      "Iterations Remaining: 1.00, Time 14.80s, Est. Time Remainig: 0.25 minnnn  Train accuracy: 0.9\n",
      "Iterations Remaining: 1.00, Time 14.78s, Est. Time Remainig: 0.25 minnnn  Train accuracy: 0.825\n",
      "Iterations Remaining: 1.00, Time 14.91s, Est. Time Remainig: 0.25 minnnn  Train accuracy: 0.925\n",
      "Iterations Remaining: 1.00, Time 14.83s, Est. Time Remainig: 0.25 minnnn  Train accuracy: 0.9\n",
      "Iterations Remaining: 1.00, Time 14.75s, Est. Time Remainig: 0.25 minnnn  Train accuracy: 0.9\n",
      "Iterations Remaining: 1.00, Time 14.73s, Est. Time Remainig: 0.25 minnnn  Train accuracy: 0.9\n",
      "Iterations Remaining: 1.00, Time 14.85s, Est. Time Remainig: 0.25 minnnn  Train accuracy: 0.95\n",
      "Iterations Remaining: 1.00, Time 14.73s, Est. Time Remainig: 0.25 minnnn  Train accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import sys\n",
    "batch_size = 40\n",
    "n_epochs = 10\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    inception_saver.restore(sess, INCEPTION_V3_CHECKPOINT_PATH)\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(len(train) // batch_size):\n",
    "            t0 = time()\n",
    "            X_batch, y_batch = prepare_batch(batch_size*iteration, batch_size, train)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "            t1 = time()\n",
    "            time_remaining = ((len(train) // batch_size)-iteration)*(t1-t0)\n",
    "            time_remaining = time_remaining/60\n",
    "            sys.stdout.write(\"\\rIterations Remaining: {0:.2f}, Time {1:.2f}s, Est. Time Remainig: {2:.2f} min\".format(((len(train) // batch_size)-iteration),((t1-t0)),time_remaining))\n",
    "            sys.stdout.flush()\n",
    "        scores = []\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        print(\"  Train accuracy:\", acc_train)\n",
    "        save_path = saver.save(sess, \"./dog_breed_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./dog_breed_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zach dunkerton\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations Remaining: 1.00, Time 39.54s, Est. Time Remainig: 0.66 minTest accuracy: 0.9066667\n"
     ]
    }
   ],
   "source": [
    "test_batch_size=150\n",
    "acc_vals = []\n",
    "from time import time\n",
    "import sys\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./dog_breed_model\")\n",
    "    for iteration in range(len(val) // test_batch_size):\n",
    "        t0 = time()\n",
    "        X_test_batch, y_test_batch = prepare_batch(test_batch_size*iteration, test_batch_size, val)\n",
    "        acc_vals.append(accuracy.eval(feed_dict={X: X_test_batch, y: y_test_batch}))\n",
    "        t1 = time()\n",
    "        time_remaining = ((len(val) // test_batch_size)-iteration)*(t1-t0)\n",
    "        time_remaining = time_remaining/60\n",
    "        sys.stdout.write(\"\\rIterations Remaining: {0:.2f}, Time {1:.2f}s, Est. Time Remainig: {2:.2f} min\".format(((len(val) // test_batch_size)-iteration),((t1-t0)),time_remaining))            \n",
    "        sys.stdout.flush()\n",
    "    acc_test = np.mean(acc_vals)\n",
    "    print(\"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
